{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importacion paquetes**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 23:56:52.608945: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Carga de datos**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coments=pd.read_csv('../seleccion_vars/coments/DatasetAirbnb_Review_Varselect_v1.csv')\n",
    "coments.drop(['user_id','apart_id','imagen','tokens'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tokenización y padding de comentarios**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(coments['text_clean'].astype(str))\n",
    "comment_sequences = tokenizer.texts_to_sequences(coments['text_clean'].astype(str))\n",
    "comment_input = pad_sequences(comment_sequences, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ubicacion', 'gender', 'rating', 'sentimiento', 'prom_long_word',\n",
       "       'num_adj', 'text_clean', 'prob_ruido', 'prob_limp', 'prob_ubi',\n",
       "       'prob_wf', 'prob_park', 'prob_bañ', 'num_toks'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coments.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conversión a tensores**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubicacion = tf.convert_to_tensor(coments['ubicacion'].values.reshape(-1, 1), dtype=tf.int32)\n",
    "genero = tf.convert_to_tensor(coments['gender'].values.reshape(-1, 1), dtype=tf.int32)\n",
    "ruido = tf.convert_to_tensor(coments['prob_ruido'].values.reshape(-1, 1), dtype=tf.int32)\n",
    "ubi = tf.convert_to_tensor(coments['prob_ubi'].values.reshape(-1, 1), dtype=tf.int32)\n",
    "wf = tf.convert_to_tensor(coments['prob_wf'].values.reshape(-1, 1), dtype=tf.int32)\n",
    "park = tf.convert_to_tensor(coments['prob_park'].values.reshape(-1, 1), dtype=tf.int32)\n",
    "ban = tf.convert_to_tensor(coments['prob_bañ'].values.reshape(-1, 1), dtype=tf.int32)\n",
    "num_toks = tf.convert_to_tensor(coments['num_toks'].values.reshape(-1, 1), dtype=tf.int32)\n",
    "limp = tf.convert_to_tensor(coments['prob_limp'].values.reshape(-1, 1), dtype=tf.int32)\n",
    "comment_input = tf.convert_to_tensor(comment_input, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = tf.convert_to_tensor(coments['rating'].values.reshape(-1, 1), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **División de los datos en train y test**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de datos en entrenamiento y validación usando indexación\n",
    "split_index = int(len(coments) * 0.8)\n",
    "\n",
    "x_train = [ubicacion[:split_index], genero[:split_index], ruido[:split_index], ubi[:split_index],wf[:split_index],park[:split_index],ban[:split_index],num_toks[:split_index],limp[:split_index], comment_input[:split_index]]\n",
    "y_train = ratings[:split_index]\n",
    "\n",
    "x_val = [ubicacion[split_index:], genero[split_index:], ruido[split_index:], ubi[split_index:],wf[split_index:],park[split_index:],ban[split_index:],num_toks[split_index:],limp[split_index:], comment_input[split_index:]]\n",
    "y_val = ratings[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parametros de entrada**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ACABAR DE ADAPTAR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de entrada\n",
    "num_users = comentarios['user_id'].nunique()\n",
    "num_items = comentarios['apart_id'].nunique()\n",
    "num_locations = comentarios['ubicacion'].nunique()\n",
    "embedding_dim = 50\n",
    "\n",
    "\n",
    "# Input layers\n",
    "user_id_input = Input(shape=(1,), name='user_id_input')\n",
    "item_id_input = Input(shape=(1,), name='item_id_input')\n",
    "location_input = Input(shape=(1,), name='location_input')\n",
    "gender_input = Input(shape=(1,), name='gender_input')\n",
    "comment_input_layer = Input(shape=(100,), name='comment_input')\n",
    "\n",
    "# Embedding layers\n",
    "user_embedding = Embedding(input_dim=num_users, output_dim=embedding_dim, name='user_embedding')(user_id_input)\n",
    "item_embedding = Embedding(input_dim=num_items, output_dim=embedding_dim, name='item_embedding')(item_id_input)\n",
    "location_embedding = Embedding(input_dim=num_locations, output_dim=embedding_dim, name='location_embedding')(location_input)\n",
    "gender_embedding = Embedding(input_dim=2, output_dim=embedding_dim, name='gender_embedding')(gender_input)  # Assuming binary gender\n",
    "\n",
    "# Flatten layers\n",
    "user_vec = Flatten(name='flatten_user')(user_embedding)\n",
    "item_vec = Flatten(name='flatten_item')(item_embedding)\n",
    "location_vec = Flatten(name='flatten_location')(location_embedding)\n",
    "gender_vec = Flatten(name='flatten_gender')(gender_embedding)\n",
    "\n",
    "# Text processing\n",
    "comment_embedding = Embedding(input_dim=5000, output_dim=embedding_dim, name='comment_embedding')(comment_input_layer)\n",
    "comment_lstm = LSTM(124)(comment_embedding)\n",
    "\n",
    "# Concatenate all features\n",
    "concat = Concatenate()([user_vec, item_vec, location_vec, gender_vec, comment_lstm])\n",
    "dense = Dense(64, activation='relu')(concat)\n",
    "dropout = Dropout(0.5)(dense)\n",
    "output = Dense(1, activation='linear')(dropout)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[user_id_input, item_id_input, location_input, gender_input, comment_input_layer], outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error',metrics=['mae', 'mse'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='best_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,  # Guardar el modelo completo\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[ model_checkpoint_callback],)\n",
    "# Making predictions for a specific user\n",
    "user_id = np.array([0])  # User ID for which you want to make predictions\n",
    "item_ids = np.array([i for i in range(num_items)])\n",
    "location = np.array([0])  # Assuming location '0' for the user\n",
    "gender = np.array([0])  # Assuming gender '0' for the user\n",
    "comment_example = pad_sequences(tokenizer.texts_to_sequences([\"example comment\"]), maxlen=100)\n",
    "predictions = model.predict([np.full_like(item_ids, user_id), item_ids, np.full_like(item_ids, location), np.full_like(item_ids, gender), np.full((len(item_ids), 100), comment_example)])\n",
    "print(\"Predicciones de recomendaciones:\", predictions.flatten())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socialnetwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
